{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "answering-battery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import opendatasets as od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "indoor-diana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  meszarosp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Kaggle Key:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                            | 1.00M/82.0M [00:00<00:08, 10.4MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading garbage-classification.zip to .\\garbage-classification\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 82.0M/82.0M [00:04<00:00, 18.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/asdasdasasdas/garbage-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "southwest-thickness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping, found downloaded files in \".\\garbage-classification\" (use force=True to force download)\n"
     ]
    }
   ],
   "source": [
    "od.download(\"https://www.kaggle.com/mostafaabla/garbage-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-republican",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "national-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "guilty-sussex",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                            | 1.00M/82.0M [00:00<00:16, 5.18MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading garbage-classification.zip to ./garbage1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 82.0M/82.0M [00:07<00:00, 11.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "api.dataset_download_files('asdasdasasdas/garbage-classification', path=\"./garbage1\", quiet=False, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "magnetic-cinema",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0.00/239M [00:00<?, ?B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading garbage-classification.zip to ./garbage2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 239M/239M [00:26<00:00, 9.50MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "api.dataset_download_files('mostafaabla/garbage-classification', path=\"./garbage2\", quiet=False, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "trying-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "naval-murray",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2527 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen_train = ImageDataGenerator(samplewise_center=True)\n",
    "\n",
    "train_it = datagen_train.flow_from_directory(\n",
    "    \"garbage1/Garbage classification/Garbage classification/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=\"categorical\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "administrative-means",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.DirectoryIterator object at 0x00000256994D0D00>\n"
     ]
    }
   ],
   "source": [
    "print(train_it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "failing-executive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image as image_utils\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_image(image_path):\n",
    "    #image = image_utils.load_img(image_path)\n",
    "    image = image_utils.load_img(image_path, target_size=(224, 224))\n",
    "    image = image_utils.img_to_array(image)\n",
    "    image = image.reshape(1,224,224,3)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "through-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = load_and_process_image('garbage1/Garbage classification/Garbage classification/cardboard/cardboard10.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "deluxe-brass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "garbage1/Garbage classification/Garbage classification\\cardboard\n",
      "garbage1/Garbage classification/Garbage classification\\glass\n",
      "garbage1/Garbage classification/Garbage classification\\metal\n",
      "garbage1/Garbage classification/Garbage classification\\paper\n",
      "garbage1/Garbage classification/Garbage classification\\plastic\n",
      "garbage1/Garbage classification/Garbage classification\\trash\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "directory = 'garbage1/Garbage classification/Garbage classification'\n",
    "classes = ['cardboard', 'glass', 'metal', 'paper', 'plastic', 'trash']\n",
    "\n",
    "images = []\n",
    "\n",
    "for classname in classes:\n",
    "    path = os.path.join(directory, classname)\n",
    "    print(path)\n",
    "    for file in os.scandir(path):\n",
    "        if '.jpg' in file.path:\n",
    "            images.append(load_image(file.path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "identical-series",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2528 files belonging to 6 classes.\n",
      "Using 2023 files for training.\n",
      "Found 2528 files belonging to 6 classes.\n",
      "Using 505 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_1 = keras.utils.image_dataset_from_directory(\n",
    "    'garbage1/Garbage classification/Garbage classification/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    image_size=(256,256),\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    subset='training'\n",
    ")\n",
    "val_1 = keras.utils.image_dataset_from_directory(\n",
    "    'garbage1/Garbage classification/Garbage classification/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    image_size=(256,256),\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "personal-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "train_1 = train.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_1 = val.map(lambda x, y: (normalization_layer(x), y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "individual-bruce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `class_names` passed did not match the names of the subdirectories of the target directory. Expected: ['battery', 'biological', 'brown-glass', 'cardboard', 'clothes', 'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass'], but received: ['cardboard', 'brown-glass', 'metal', 'paper', 'plastic', 'trash']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-5f795cb86dad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_2 = keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;34m'garbage2/garbage_classification/'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inferred'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mlabel_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mclass_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'cardboard'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'brown-glass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'metal'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'paper'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'plastic'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'trash'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda\\lib\\site-packages\\keras\\preprocessing\\image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[1;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1e6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m   image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[0;32m    193\u001b[0m       \u001b[0mdirectory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m       \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Miniconda\\lib\\site-packages\\keras\\preprocessing\\dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[1;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubdirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[1;34m'The `class_names` passed did not match the '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;34m'names of the subdirectories of the target directory. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The `class_names` passed did not match the names of the subdirectories of the target directory. Expected: ['battery', 'biological', 'brown-glass', 'cardboard', 'clothes', 'green-glass', 'metal', 'paper', 'plastic', 'shoes', 'trash', 'white-glass'], but received: ['cardboard', 'brown-glass', 'metal', 'paper', 'plastic', 'trash']"
     ]
    }
   ],
   "source": [
    "train_2 = keras.utils.image_dataset_from_directory(\n",
    "    'garbage2/garbage_classification/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    class_names=['cardboard', 'brown-glass', 'metal', 'paper', 'plastic', 'trash'],\n",
    "    batch_size=1,\n",
    "    image_size=(256,256),\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    subset='training'\n",
    ")\n",
    "val_2 = keras.utils.image_dataset_from_directory(\n",
    "    'garbage2/garbage_classification/',\n",
    "    labels='inferred',\n",
    "    label_mode='categorical',\n",
    "    batch_size=1,\n",
    "    image_size=(256,256),\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "eleven-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "shutil.rmtree('garbage2/garbage_classification/battery')\n",
    "shutil.rmtree('garbage2/garbage_classification/clothes')\n",
    "shutil.rmtree('garbage2/garbage_classification/biological')\n",
    "shutil.rmtree('garbage2/garbage_classification/shoes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "western-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('garbage2/garbage_classification/brown-glass', 'garbage2/garbage_classification/glass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "japanese-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('garbage2/garbage_classification/green-glass'):\n",
    "    shutil.move(os.path.join('garbage2/garbage_classification/green-glass', filename), os.path.join('garbage2/garbage_classification/glass', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "adjacent-advantage",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in os.listdir('garbage2/garbage_classification/white-glass'):\n",
    "    shutil.move(os.path.join('garbage2/garbage_classification/white-glass', filename), os.path.join('garbage2/garbage_classification/glass', filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "gorgeous-thesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir('garbage2/garbage_classification/green-glass')\n",
    "os.rmdir('garbage2/garbage_classification/white-glass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-completion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
